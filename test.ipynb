{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5393d6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from tqdm import tqdm \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e35d5ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams \n",
    "device = torch.device(\"cpu\")\n",
    "block_size = 64\n",
    "batch_size = 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader \n",
    "data_path = Path(\"data/tiny.txt\")\n",
    "assert data_path.exists(), \"Create data/text.txt with some text\"\n",
    "text = data_path.read_text(encoding=\"utf-8\")\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}  #This builds a dictionary (mapping) from each character (ch) to a number (i).\n",
    "itos = {i:ch for ch,i in stoi.items()} # This does the reverse of stoi: creates a dictionary that maps each number back to a character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59c932ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(s):\n",
    "    \"\"\"\n",
    "    This function takes in a string as an input and returns its numerical representation based on the stoi mappings \n",
    "    \"\"\"\n",
    "    return [stoi[c] for c in s]\n",
    "\n",
    "def decode(l): \n",
    "    \"\"\"\n",
    "    Takes in a list of numbers and returns a string based in itos mappings \n",
    "    \"\"\"\n",
    "    return \"\".join(itos[i] for i in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86d0bd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25, 1, 29, 22, 33, 21, 28, 1, 35, 21, 28, 33, 1, 42, 45, 55, 44, 45, 50, 43]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = encode(text)\n",
    "\n",
    "pairs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e353085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I OFTEN WENT fishing'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_pairs = decode(pairs)\n",
    "\n",
    "decode_pairs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = len(data)\n",
    "train_data = data[: int(0.9 * n)]\n",
    "val_data = data[int(0.9 * n):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59b247ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    src = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(src) - block_size, (batch_size,))\n",
    "    x = torch.stack([src[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([src[i+1:i+block_size+1] for i in ix])\n",
    "    return x.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b80531d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[40,  1, 55, 51, 49, 41, 56, 44, 45, 50, 43,  8,  1, 24, 51, 59,  1, 37,\n",
       "         38, 51, 57, 56,  1, 56, 44, 41,  1, 56, 45, 49, 41,  1, 61, 51, 57,  1,\n",
       "         43, 37, 58, 41,  1, 37,  0,  1, 48, 37, 54, 43, 41,  1, 39, 51, 50, 56,\n",
       "         54, 45, 38, 57, 56, 45, 51, 50,  1, 56],\n",
       "        [ 1, 61, 51, 57,  1, 59, 41, 54, 41,  1, 38, 51, 54, 50,  1, 59, 37, 55,\n",
       "          0,  1, 52, 41, 54, 42, 51, 54, 49, 41, 40,  1, 38, 41, 39, 37, 57, 55,\n",
       "         41,  1, 61, 51, 57,  1, 59, 37, 50, 56, 41, 40,  1, 55, 51, 49, 41, 56,\n",
       "         44, 45, 50, 43,  8,  1, 24, 51, 59,  1],\n",
       "        [54, 56, 44,  1, 37,  1, 48, 51, 56,  1, 56, 51,  1, 37,  1, 44, 51, 56,\n",
       "         41, 48,  6,  1, 45, 55, 50, 65, 56,  1, 45, 56, 16, 65,  0,  1, 17, 55,\n",
       "          1, 25,  1, 56, 37, 48, 47, 41, 40,  6,  1, 25,  1, 59, 54, 51, 56, 41,\n",
       "          1, 56, 44, 41, 55, 41,  1, 56, 59, 51],\n",
       "        [51,  1, 48, 51, 51, 47,  1, 37, 56,  1, 61, 51, 57, 54,  1, 44, 51, 56,\n",
       "         41, 48,  1, 37, 55,  1, 25,  0,  1, 39, 37, 50,  1, 38, 54, 45, 50, 43,\n",
       "          1, 38, 61,  1, 56, 44, 41, 55, 41,  1, 48, 41, 39, 56, 57, 54, 41, 55,\n",
       "          8,  1, 33, 44, 37, 56,  1, 45, 55,  1],\n",
       "        [37, 50, 56, 41, 40, 14,  1, 21, 49, 41, 54, 55, 51, 50,  1, 52, 57, 55,\n",
       "         44, 41, 40,  0,  1, 37, 50, 40,  1, 44, 45, 55,  1, 55, 51, 50,  1, 52,\n",
       "         57, 48, 48, 41, 40,  8,  1, 18, 57, 56,  1, 56, 44, 41,  1, 39, 37, 48,\n",
       "         42,  1, 59, 37, 55,  1, 40, 51, 45, 50],\n",
       "        [56, 37, 50,  1, 39, 37, 49, 41,  1, 44, 51, 49, 41,  1, 42, 54, 51, 49,\n",
       "          1, 59, 51, 54, 47,  1, 51, 50, 41,  1, 41, 58, 41, 50, 45, 50, 43,  0,\n",
       "          1, 56, 51,  1, 42, 45, 50, 40,  1, 44, 45, 55,  1, 61, 51, 57, 50, 43,\n",
       "         41, 55, 56,  1, 55, 51, 50,  6,  1, 33],\n",
       "        [ 1, 38, 37, 50, 45, 55, 44,  1, 56, 44, 41,  1, 39, 44, 45, 48, 40,  1,\n",
       "         56, 51,  0,  1, 44, 45, 55,  1, 54, 51, 51, 49,  1, 37, 50, 40,  1, 56,\n",
       "         41, 48, 48,  1, 44, 45, 49,  1, 44, 41, 65, 40,  1, 38, 41, 56, 56, 41,\n",
       "         54,  1, 49, 37, 47, 41,  1, 57, 52,  1],\n",
       "        [ 1, 45, 56,  1, 59, 37, 55,  1, 50, 41, 39, 41, 55, 55, 37, 54, 61,  1,\n",
       "         56, 51,  1, 38, 37, 45, 56,  0,  1, 56, 44, 41,  1, 44, 51, 51, 47,  1,\n",
       "         56, 51,  1, 55, 57, 45, 56,  1, 56, 44, 41,  1, 42, 45, 55, 44,  8,  0,\n",
       "          1, 35, 44, 61,  1, 56, 37, 48, 47,  1],\n",
       "        [37, 50, 40,  1, 38, 37, 48, 48, 54, 51, 51, 49,  1, 51, 42,  1, 37,  1,\n",
       "         39, 41, 54, 56, 37, 45, 50,  1, 28, 41, 59,  1, 36, 51, 54, 47,  1, 44,\n",
       "         51, 56, 41, 48,  1, 42, 51, 54,  0,  1, 56, 59, 41, 50, 56, 61,  1, 50,\n",
       "         45, 43, 44, 56, 55,  1, 45, 50,  1, 41],\n",
       "        [41, 56, 44, 41, 54,  1, 61, 51, 57,  1, 37, 54, 41,  1, 40, 41, 37, 48,\n",
       "         45, 50, 43,  0,  1, 59, 45, 56, 44,  1, 39, 44, 45, 48, 40, 54, 41, 50,\n",
       "          1, 51, 54,  1, 39, 37, 48, 58, 41, 55,  1, 51, 54,  1, 39, 44, 45, 49,\n",
       "         52, 37, 50, 62, 41, 41, 55,  8,  1, 22],\n",
       "        [44, 51, 57, 54,  1, 37, 50, 40,  1, 42, 45, 50, 37, 48, 48, 61,  1, 43,\n",
       "         37, 58, 41,  1, 37, 59, 37, 61,  1,  3, 10, 12, 11,  1, 49, 45, 48, 48,\n",
       "         45, 51, 50,  6,  1, 48, 41, 37, 54, 50, 41, 40,  1, 41, 37, 54, 48, 61,\n",
       "          1, 45, 50,  0,  1, 48, 45, 42, 41,  1],\n",
       "        [50, 56,  8, 65,  0,  1, 33, 44, 41, 50,  1, 25,  1, 56, 51, 51, 47,  1,\n",
       "         37,  1, 48, 41, 56, 56, 41, 54, 44, 41, 37, 40,  1, 37, 50, 40,  1, 54,\n",
       "         37, 50,  1, 37,  1, 48, 45, 50, 41,  1, 56, 44, 54, 51, 57, 43, 44,  1,\n",
       "         56, 44, 41,  1, 39, 41, 50, 56, 54, 41]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = get_batch(split=\"train\")\n",
    "\n",
    "batches[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "857ff437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1880676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Setup ---\n",
    "# Suppose we have 4 tokens (\"I\", \"love\", \"machine\", \"learning\")\n",
    "# and each token is represented by an embedding vector of size 8.\n",
    "torch.manual_seed(0)\n",
    "x = torch.randn(1, 4, 8)  # (batch=1, seq_len=4, embed_dim=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "232fde24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1258, -1.1524, -0.2506, -0.4339,  0.8487,  0.6920, -0.3160,\n",
       "          -2.1152],\n",
       "         [ 0.3223, -1.2633,  0.3500,  0.3081,  0.1198,  1.2377,  1.1168,\n",
       "          -0.2473],\n",
       "         [-1.3527, -1.6959,  0.5667,  0.7935,  0.5988, -1.5551, -0.3414,\n",
       "           1.8530],\n",
       "         [ 0.7502, -0.5855, -0.1734,  0.1835,  1.3894,  1.5863,  0.9463,\n",
       "          -0.8437]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f1f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use 2 heads\n",
    "n_heads = 2\n",
    "head_dim = x.size(-1) // n_heads  # 8 / 2 = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49bbd8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of dime|nsions in each head \n",
    "head_dim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af7c5a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define learnable weights for Q, K, V ---\n",
    "W_q = torch.randn(8, 8)\n",
    "W_k = torch.randn(8, 8)\n",
    "W_v = torch.randn(8, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0077211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.1358e-01,  3.1593e-02, -4.9268e-01,  2.4841e-01,  4.3970e-01,\n",
       "          1.1241e-01,  6.4079e-01,  4.4116e-01],\n",
       "        [-1.0231e-01,  7.9244e-01, -2.8967e-01,  5.2507e-02,  5.2286e-01,\n",
       "          2.3022e+00, -1.4689e+00, -1.5867e+00],\n",
       "        [-6.7309e-01,  8.7283e-01,  1.0554e+00,  1.7784e-01, -2.3034e-01,\n",
       "         -3.9175e-01,  5.4329e-01, -3.9516e-01],\n",
       "        [-4.4622e-01,  7.4402e-01,  1.5210e+00,  3.4105e+00, -1.5312e+00,\n",
       "         -1.2341e+00,  1.8197e+00, -5.5153e-01],\n",
       "        [-5.6925e-01,  9.1997e-01,  1.1108e+00,  1.2899e+00, -1.4782e+00,\n",
       "          2.5672e+00, -4.7312e-01,  3.3555e-01],\n",
       "        [-1.6293e+00, -5.4974e-01, -4.7983e-01, -4.9968e-01, -1.0670e+00,\n",
       "          1.1149e+00, -1.4067e-01,  8.0575e-01],\n",
       "        [-9.3348e-02,  6.8705e-01, -8.3832e-01,  8.9182e-04,  8.4189e-01,\n",
       "         -4.0003e-01,  1.0395e+00,  3.5815e-01],\n",
       "        [-2.4600e-01,  2.3025e+00, -1.8817e+00, -4.9727e-02, -1.0450e+00,\n",
       "         -9.5650e-01,  3.3532e-02,  7.1009e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c455e853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6459, -1.3602,  0.3446,  0.5199, -2.6133, -1.6965, -0.2282,  0.2800],\n",
       "        [ 0.2469,  0.0769,  0.3380,  0.4544,  0.4569, -0.8654,  0.7813, -0.9268],\n",
       "        [-0.2188, -2.4351, -0.0729, -0.0340,  0.9625,  0.3492, -0.9215, -0.0562],\n",
       "        [-0.6227, -0.4637,  1.9218, -0.4025,  0.1239,  1.1648,  0.9234,  1.3873],\n",
       "        [-0.8834, -0.4189, -0.8048,  0.5656,  0.6104,  0.4669,  1.9507, -1.0631],\n",
       "        [-0.0773,  0.1164, -0.5940, -1.2439, -0.1021, -1.0335, -0.3126,  0.2458],\n",
       "        [-0.2596,  0.1183,  0.2440,  1.1646,  0.2886,  0.3866, -0.2011, -0.1179],\n",
       "        [ 0.1922, -0.7722, -1.9003,  0.1307, -0.7043,  0.3147,  0.1574,  0.3854]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dcb4cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9671, -0.9911,  0.3016, -0.1073,  0.9985, -0.4987,  0.7611,  0.6183],\n",
       "        [ 0.3140,  0.2133, -0.1201,  0.3605, -0.3140, -1.0787,  0.2408, -1.3962],\n",
       "        [-0.0661, -0.3584, -1.5616, -0.3546,  1.0811,  0.1315,  1.5735,  0.7814],\n",
       "        [-1.0787, -0.7209,  1.4708,  0.2756,  0.6668, -0.9944, -1.1894, -1.1959],\n",
       "        [-0.5596,  0.5335,  0.4069,  0.3946,  0.1715,  0.8760, -0.2871,  1.0216],\n",
       "        [-0.0744, -1.0922,  0.3920,  0.5945,  0.6623, -1.2063,  0.6074, -0.5472],\n",
       "        [ 1.1711,  0.0975,  0.9634,  0.8403, -1.2537,  0.9868, -0.4947, -1.2830],\n",
       "        [ 0.9552,  1.2836, -0.6659,  0.5651,  0.2877, -0.0334, -1.0619, -0.1144]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fcc8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Q, K, V ---\n",
    "Q = x @ W_q    # (1, 4, 8) x.W_q\n",
    "K = x @ W_k    # (1, 4, 8) x.W_k\n",
    "V = x @ W_v    # (1, 4, 8) x.W_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d914ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1102, -6.1774,  4.8199, -1.0106, -0.4241,  2.9541, -0.8527,\n",
       "           0.8973],\n",
       "         [-2.5697, -0.8284,  0.1135,  0.6763, -1.3704, -1.9123,  3.7348,\n",
       "           3.1003],\n",
       "         [ 2.0369,  5.1362,  1.1734,  3.8390, -4.2767, -7.0900,  3.0189,\n",
       "           1.5741],\n",
       "         [-3.6219, -1.3414,  1.4725,  1.7928, -2.2853,  4.3418,  1.6553,\n",
       "           2.7115]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a91606c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.9403,  3.5750,  1.2555, -1.9510,  3.9666,  1.2075,  0.3567,\n",
       "          -1.3451],\n",
       "         [-0.5890, -1.1137,  0.1614, -0.7459, -0.6012,  0.1583, -1.5152,\n",
       "           1.6187],\n",
       "         [-3.2272, -1.9414, -2.7186,  0.3052,  2.5244,  7.2225,  1.2088,\n",
       "           1.9976],\n",
       "         [-0.7440, -0.3622,  0.1995, -0.1397, -0.8188, -1.5034,  1.5917,\n",
       "          -0.5069]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "322f867e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.8832, -1.7764,  1.2725, -1.0399, -0.9309,  1.8705,  1.5665,\n",
       "           2.3719],\n",
       "         [ 0.4719, -2.4329,  1.9300,  1.0527,  0.6714,  0.6640,  0.5529,\n",
       "          -0.0912],\n",
       "         [-1.5834,  4.5669, -1.8508, -0.3763,  0.3576,  3.7913, -4.4054,\n",
       "           2.7140],\n",
       "         [-0.2380, -2.9206,  3.4978,  1.6303,  0.7276,  0.3178,  0.9314,\n",
       "           0.3603]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f548ba84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q shape: torch.Size([1, 4, 8])\n",
      "K shape: torch.Size([1, 4, 8])\n",
      "V shape: torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Q shape:\", Q.shape)\n",
    "print(\"K shape:\", K.shape)\n",
    "print(\"V shape:\", V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffc10d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into heads \n",
    "# We reshape (batch, seq_len, embed_dim) → (batch, n_heads, seq_len, head_dim)\n",
    "def split_heads(tensor):\n",
    "    b, seq_len, embed_dim = tensor.size()\n",
    "    return tensor.view(b, seq_len, n_heads, head_dim).transpose(1, 2)\n",
    "    # Transpose so shape = (batch, heads, seq_len, head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47c2bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_heads = split_heads(Q)\n",
    "K_heads = split_heads(K)\n",
    "V_heads = split_heads(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5ffac46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1102, -6.1774,  4.8199, -1.0106],\n",
       "          [-2.5697, -0.8284,  0.1135,  0.6763],\n",
       "          [ 2.0369,  5.1362,  1.1734,  3.8390],\n",
       "          [-3.6219, -1.3414,  1.4725,  1.7928]],\n",
       "\n",
       "         [[-0.4241,  2.9541, -0.8527,  0.8973],\n",
       "          [-1.3704, -1.9123,  3.7348,  3.1003],\n",
       "          [-4.2767, -7.0900,  3.0189,  1.5741],\n",
       "          [-2.2853,  4.3418,  1.6553,  2.7115]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "071b2276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.9403,  3.5750,  1.2555, -1.9510],\n",
       "          [-0.5890, -1.1137,  0.1614, -0.7459],\n",
       "          [-3.2272, -1.9414, -2.7186,  0.3052],\n",
       "          [-0.7440, -0.3622,  0.1995, -0.1397]],\n",
       "\n",
       "         [[ 3.9666,  1.2075,  0.3567, -1.3451],\n",
       "          [-0.6012,  0.1583, -1.5152,  1.6187],\n",
       "          [ 2.5244,  7.2225,  1.2088,  1.9976],\n",
       "          [-0.8188, -1.5034,  1.5917, -0.5069]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45ad585d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-3.8832, -1.7764,  1.2725, -1.0399],\n",
       "          [ 0.4719, -2.4329,  1.9300,  1.0527],\n",
       "          [-1.5834,  4.5669, -1.8508, -0.3763],\n",
       "          [-0.2380, -2.9206,  3.4978,  1.6303]],\n",
       "\n",
       "         [[-0.9309,  1.8705,  1.5665,  2.3719],\n",
       "          [ 0.6714,  0.6640,  0.5529, -0.0912],\n",
       "          [ 0.3576,  3.7913, -4.4054,  2.7140],\n",
       "          [ 0.7276,  0.3178,  0.9314,  0.3603]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5767a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5: Compute attention scores for each head ---\n",
    "scores = torch.matmul(Q_heads, K_heads.transpose(-2, -1)) / (head_dim ** 0.5) # Simply QKt \n",
    "# Q = 4x4 matrix \n",
    "# K = 4x4 matrix \n",
    "# Kt = 4X4 \n",
    "# Therefore QKt will result to a 4x4 matrix output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9743a815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ -7.1925,   4.1732,  -0.8871,   1.6291],\n",
       "          [  1.7086,   0.9751,   4.8995,   1.0701],\n",
       "          [  3.1781,  -4.7970,  -9.2815,  -1.8389],\n",
       "          [  2.1023,   1.2639,   5.4185,   1.6120]],\n",
       "\n",
       "         [[  0.1869,   1.7336,  10.5136,  -2.9530],\n",
       "          [ -5.2913,  -0.0598,  -3.2815,   4.1851],\n",
       "          [-13.2826,  -0.2889, -27.6053,   9.0842],\n",
       "          [ -3.4395,   1.9712,  16.5036,  -1.6980]]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5f0bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply softmax to get attention weights ---\n",
    "attn_weights = F.softmax(scores, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78cfeede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0679e-05, 9.2175e-01, 5.8467e-03, 7.2394e-02],\n",
       "          [3.7994e-02, 1.8246e-02, 9.2370e-01, 2.0064e-02],\n",
       "          [9.9308e-01, 3.4153e-04, 3.8531e-06, 6.5782e-03],\n",
       "          [3.3786e-02, 1.4608e-02, 9.3091e-01, 2.0691e-02]],\n",
       "\n",
       "         [[3.2739e-05, 1.5374e-04, 9.9981e-01, 1.4172e-06],\n",
       "          [7.5512e-05, 1.4126e-02, 5.6347e-04, 9.8523e-01],\n",
       "          [1.9327e-10, 8.4972e-05, 1.1639e-16, 9.9992e-01],\n",
       "          [2.1818e-09, 4.8823e-07, 1.0000e+00, 1.2449e-08]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f37a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply weights by V to get attention outputs ---\n",
    "head_outputs = torch.matmul(attn_weights, V_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "646158d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4085, -2.4272,  2.0214,  1.0861],\n",
       "          [-1.6063,  4.0479, -1.5559, -0.3352],\n",
       "          [-3.8577, -1.7841,  1.2874, -1.0216],\n",
       "          [-1.6032,  4.0954, -1.5794, -0.3363]],\n",
       "\n",
       "         [[ 0.3576,  3.7907, -4.4045,  2.7135],\n",
       "          [ 0.7265,  0.3247,  0.9231,  0.3554],\n",
       "          [ 0.7276,  0.3178,  0.9314,  0.3602],\n",
       "          [ 0.3576,  3.7913, -4.4054,  2.7140]]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "125c850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate heads back together ---\n",
    "# (batch, heads, seq_len, head_dim) → (batch, seq_len, embed_dim)\n",
    "combined = head_outputs.transpose(1, 2).contiguous().view(1, 4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29f839ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4085, -2.4272,  2.0214,  1.0861,  0.3576,  3.7907, -4.4045,\n",
       "           2.7135],\n",
       "         [-1.6063,  4.0479, -1.5559, -0.3352,  0.7265,  0.3247,  0.9231,\n",
       "           0.3554],\n",
       "         [-3.8577, -1.7841,  1.2874, -1.0216,  0.7276,  0.3178,  0.9314,\n",
       "           0.3602],\n",
       "         [-1.6032,  4.0954, -1.5794, -0.3363,  0.3576,  3.7913, -4.4054,\n",
       "           2.7140]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined # 4x8 matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea4b65a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_o = torch.randn(8, 8)\n",
    "out = combined @ W_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04c5e7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -2.2239,   4.5809,   3.1000,  -8.3132,   8.8128, -10.4970,  11.6042,\n",
       "           12.2652],\n",
       "         [  2.0165,  -1.3627,  -2.3379,   4.4722,  -7.3122,   1.6044,   3.8696,\n",
       "           -5.5359],\n",
       "         [ -0.5414,  -7.4888,  -0.1208,  -4.1437,   2.8600,  -5.1260,  -1.8987,\n",
       "            6.9527],\n",
       "         [  2.9528,   2.7813,  -2.2634,   1.1013,  -0.6279,  -6.1177,  14.9080,\n",
       "            3.5088]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04b5eb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3433,  1.5713,  0.1916,  0.3799, -0.1448,  0.6376, -0.2813, -1.3299],\n",
       "        [-0.1420, -0.5341, -0.5234,  0.8615, -0.8870,  0.8388,  1.1529, -1.7611],\n",
       "        [-1.4777, -1.7557,  0.0762, -1.0786,  1.4403, -0.1106,  0.5769, -0.1692],\n",
       "        [-0.0640,  1.0384,  0.9068, -0.4755, -0.8707,  0.1447,  1.9029,  0.3904],\n",
       "        [-0.0394, -0.8015, -0.4955, -0.3615,  0.5851, -1.1560, -0.1434, -0.1947],\n",
       "        [-0.0856,  1.3945,  0.5969, -0.4828, -0.3661, -1.3271,  1.6953,  2.0655],\n",
       "        [-0.2340,  0.7073,  0.5800,  0.2683, -2.0589,  0.5340, -0.5354, -0.8637],\n",
       "        [-0.0235,  1.1717,  0.3987, -0.1987, -1.1559, -0.3167,  0.9403, -1.1470]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f86d347",
   "metadata": {},
   "source": [
    "## How to compute Q, K, V with one combined linear layer (step-by-step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf721de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
